{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Predicting the gender of voice\n","\n","The goal of this project is to develop a machine learning pipeline to classify voices as either male or female, based on the acoustic properties of the voice and speech by running a logistic regression from `spark.ml` on data from Kaggle's [voice.csv](https://www.kaggle.com/primaryobjects/voicegender/data) dataset.\n","\n","The following acoustic properties of each voice are measured and included within the CSV:\n","\n","* `meanfreq`: mean frequency (in kHz)\n","* `sd`: standard deviation of frequency\n","* `median`: median frequency (in kHz)\n","* `Q25`: first quantile (in kHz)\n","* `Q75`: third quantile (in kHz)\n","* `IQR`: interquantile range (in kHz)\n","* `skew`: skewness (see note in specprop description)\n","* `kurt`: kurtosis (see note in specprop description)\n","* `sp.ent`: spectral entropy\n","* `sfm`: spectral flatness\n","* `mode`: mode frequency\n","* `centroid`: frequency centroid (see specprop)\n","* `peakf`: peak frequency (frequency with highest energy)\n","* `meanfun`: average of fundamental frequency measured across acoustic signal\n","* `minfun`: minimum fundamental frequency measured across acoustic signal\n","* `maxfun`: maximum fundamental frequency measured across acoustic signal\n","* `meandom`: average of dominant frequency measured across acoustic signal\n","* `mindom`: minimum of dominant frequency measured across acoustic signal\n","* `maxdom`: maximum of dominant frequency measured across acoustic signal\n","* `dfrange`: range of dominant frequency measured across acoustic signal\n","* `modindx`: modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range\n","* `label`: male or female"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pyspark.sql.types as typ\n","from pyspark.sql.types import *\n","import pyspark.ml.feature as ft\n","import pyspark.ml.classification as cl\n","from pyspark.ml import Pipeline\n","\n","# libraries for model tuning\n","import pyspark.ml.tuning as tune\n","import pyspark.ml.evaluation as ev"]},{"cell_type":"markdown","metadata":{},"source":["## Data loading and preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["After downloading the dataset into the master node of the cluster and copying it into Hadoop in the `tmp` folder, we can move on to preprocessing."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["voice_path = \"/tmp/voice.csv\""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# metadata / schema for the voice.csv dataset\n","schema = StructType([\n","    StructField(\"meanfreq\", DoubleType(), True),    \n","    StructField(\"sd\", DoubleType(), True),\n","    StructField(\"median\", DoubleType(), True),\n","    StructField(\"Q25\", DoubleType(), True),\n","    StructField(\"Q75\", DoubleType(), True),\n","    StructField(\"IQR\", DoubleType(), True),\n","    StructField(\"skew\", DoubleType(), True),\n","    StructField(\"kurt\", DoubleType(), True),\n","    StructField(\"sp_ent\", DoubleType(), True),\n","    StructField(\"sfm\", DoubleType(), True),\n","    StructField(\"mode\", DoubleType(), True),\n","    StructField(\"centroid\", DoubleType(), True),\n","    StructField(\"meanfun\", DoubleType(), True),\n","    StructField(\"minfun\", DoubleType(), True),\n","    StructField(\"maxfun\", DoubleType(), True),\n","    StructField(\"meandom\", DoubleType(), True),\n","    StructField(\"mindom\", DoubleType(), True),\n","    StructField(\"maxdom\", DoubleType(), True),\n","    StructField(\"dfrange\", DoubleType(), True),\n","    StructField(\"modindx\", DoubleType(), True),\n","    StructField(\"label\", StringType(), True)    \n","])\n","\n","# loading the data into a dataframe using the schema defined above\n","voice = spark.read.csv(voice_path, header=True, schema=schema)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 0:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+------------------+------------------+-----------------+------------------+------------------+------------------+----------------+----------------+-----------------+-----------------+----+------------------+-----------------+------------------+-----------------+---------+---------+---------+-------+-------+-----+\n","|          meanfreq|                sd|           median|               Q25|               Q75|               IQR|            skew|            kurt|           sp_ent|              sfm|mode|          centroid|          meanfun|            minfun|           maxfun|  meandom|   mindom|   maxdom|dfrange|modindx|label|\n","+------------------+------------------+-----------------+------------------+------------------+------------------+----------------+----------------+-----------------+-----------------+----+------------------+-----------------+------------------+-----------------+---------+---------+---------+-------+-------+-----+\n","|0.0597809849598081|0.0642412677031359|0.032026913372582|0.0150714886459209|0.0901934398654331|0.0751219512195122|12.8634618371626|274.402905502067|0.893369416700807|0.491917766397811| 0.0|0.0597809849598081|0.084279106440321|0.0157016683022571|0.275862068965517|0.0078125|0.0078125|0.0078125|    0.0|    0.0| male|\n","+------------------+------------------+-----------------+------------------+------------------+------------------+----------------+----------------+-----------------+-----------------+----+------------------+-----------------+------------------+-----------------+---------+---------+---------+-------+-------+-----+\n","only showing top 1 row\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# dataset structure and sample instance\n","voice.show(1)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["3168"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["voice.count()"]},{"cell_type":"markdown","metadata":{},"source":["This is the size of the dataset; i.e., it contains 3,168 recorded voice samples."]},{"cell_type":"markdown","metadata":{},"source":["### Converting the data into correct format\n","\n","We need to cast the gender labels into integer values (instead of `StringType`) before fitting the model:"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- meanfreq: double (nullable = true)\n"," |-- sd: double (nullable = true)\n"," |-- median: double (nullable = true)\n"," |-- Q25: double (nullable = true)\n"," |-- Q75: double (nullable = true)\n"," |-- IQR: double (nullable = true)\n"," |-- skew: double (nullable = true)\n"," |-- kurt: double (nullable = true)\n"," |-- sp_ent: double (nullable = true)\n"," |-- sfm: double (nullable = true)\n"," |-- mode: double (nullable = true)\n"," |-- centroid: double (nullable = true)\n"," |-- meanfun: double (nullable = true)\n"," |-- minfun: double (nullable = true)\n"," |-- maxfun: double (nullable = true)\n"," |-- meandom: double (nullable = true)\n"," |-- mindom: double (nullable = true)\n"," |-- maxdom: double (nullable = true)\n"," |-- dfrange: double (nullable = true)\n"," |-- modindx: double (nullable = true)\n"," |-- label: integer (nullable = true)\n","\n"]}],"source":["voice = voice.withColumn(\"label\", (voice[\"label\"]==\"male\").cast(IntegerType()))\n","voice.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["### Split the data into training and testing samples"]},{"cell_type":"markdown","metadata":{},"source":["We will split the data set to get 70% training data and 30% testing data."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Voice_train shape:  2227\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 7:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":[" Voice_test shape:  941\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# split data into training (70% of the samples) and testing (30% of the samples)\n","voice_train, voice_test = voice.randomSplit([0.7, 0.3], seed=1)\n","print(\"Voice_train shape: \", voice_train.count())\n","print(\" Voice_test shape: \", voice_test.count())"]},{"cell_type":"markdown","metadata":{},"source":["## Using pipeline to fit the logistic regression\n","\n","We use an **ML (machine learning) pipeline** which chains multiple transformers and estimators together to specify an ML workflow. One advantage of this paradigm is that we can use the same transformations for training and testing the data. For training, we need to plug in an estimator in the end. For testing, we need to plug in the model that has been produced by the estimator."]},{"cell_type":"markdown","metadata":{},"source":["### Creating transformers\n","\n","Now, we will be defining a transformer (`VectorAssembler`) which creates a single column with all the features collated together. Here, this will be the feature vector."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["featuresCreator = ft.VectorAssembler(\n","    inputCols = voice.columns[:-1],  # input columns\n","    outputCol = 'features'           # output is a single column with all the features\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/09/04 23:51:49 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","                                                                                \r"]},{"data":{"text/plain":["DenseVector([0.0598, 0.0642, 0.032, 0.0151, 0.0902, 0.0751, 12.8635, 274.4029, 0.8934, 0.4919, 0.0, 0.0598, 0.0843, 0.0157, 0.2759, 0.0078, 0.0078, 0.0078, 0.0, 0.0])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["featuresCreator.transform(voice).head().features"]},{"cell_type":"markdown","metadata":{},"source":["### Creating an estimator \n","\n","We will instantiate a **logistic regression model** with specific parameters:"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["lr_model = cl.LogisticRegression(  # logistic regression model \n","    maxIter = 10,                  # maximum number of iterations (>= 0)\n","    regParam = 0.01,               # regularization parameter (>= 0)\n","    labelCol = 'label')            # label column name."]},{"cell_type":"markdown","metadata":{},"source":["### Creating a pipeline \n","\n","We will now create an abstract list of transformers and estimators:"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["pipeline = Pipeline(stages=[\n","        featuresCreator, # transformer\n","        lr_model         # estimator\n","    ])"]},{"cell_type":"markdown","metadata":{},"source":["## Hyper-parameter tuning"]},{"cell_type":"markdown","metadata":{},"source":["### Grid search"]},{"cell_type":"markdown","metadata":{},"source":["We want to figure out which training parameters work well using grid search - so, we will specify our model and the list of parameters we want to loop through. Specifically, we will test the different maximum numbers of iterations and regularistaion parameters (L2). "]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["logistic = cl.LogisticRegression(labelCol = 'label')\n","\n","# we can build a grid and add the parameters we want to tune\n","grid = tune.ParamGridBuilder() \\\n","    .addGrid(logistic.maxIter, [2, 10, 50]) \\\n","    .addGrid(logistic.regParam, [0.01, 0.05, 0.3]) \\\n","    .build()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# for binary classification error estimation\n","evaluator = ev.BinaryClassificationEvaluator( \n","    rawPredictionCol = 'probability', \n","    labelCol = 'label')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# cross-validation setup\n","cv = tune.CrossValidator(\n","    estimator = logistic, \n","    estimatorParamMaps = grid, \n","    evaluator = evaluator\n",")"]},{"cell_type":"markdown","metadata":{},"source":["We will now create a purely transforming `Pipeline`, run it and estimate our model."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# running the pipeline over the training data by applying the transformer (featuresCreator) and \n","# generating a trained logistic regression model \n","pipeline = Pipeline(stages = [featuresCreator])\n","data_transformer = pipeline.fit(voice_train)"]},{"cell_type":"markdown","metadata":{},"source":["We can now check for the optimal combination of parameters for our model."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["cvModel = cv.fit(data_transformer.transform(voice_train))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["([{'maxIter': 50}, {'regParam': 0.01}], 0.9925411535016605)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["results = [\n","    (\n","        [\n","            {key.name: paramValue} \n","            for key, paramValue \n","            in zip(\n","                params.keys(), \n","                params.values())\n","        ], metric\n","    ) \n","    for params, metric \n","    in zip(\n","        cvModel.getEstimatorParamMaps(), \n","        cvModel.avgMetrics\n","    )\n","]\n","\n","sorted(results, \n","       key=lambda el: el[1], \n","       reverse=True)[0]"]},{"cell_type":"markdown","metadata":{},"source":["## Model evaluation"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["data_train = data_transformer.transform(voice_test)\n","results = cvModel.transform(data_train)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["[Row(meanfreq=0.0621823118609672, sd=0.0878894037873831, median=0.0109745762711864, Q25=0.00177966101694915, Q75=0.117457627118644, IQR=0.115677966101695, skew=9.61220808953177, kurt=114.803500510109, sp_ent=0.786650358576641, sfm=0.329569856469261, mode=0.000889830508474576, centroid=0.0621823118609672, meanfun=0.0997761550401998, minfun=0.0171122994652406, maxfun=0.258064516129032, meandom=0.0955528846153846, mindom=0.0078125, maxdom=1.4140625, dfrange=1.40625, modindx=0.105777777777778, label=1, features=DenseVector([0.0622, 0.0879, 0.011, 0.0018, 0.1175, 0.1157, 9.6122, 114.8035, 0.7867, 0.3296, 0.0009, 0.0622, 0.0998, 0.0171, 0.2581, 0.0956, 0.0078, 1.4141, 1.4062, 0.1058]), rawPrediction=DenseVector([-2.689, 2.689]), probability=DenseVector([0.0636, 0.9364]), prediction=1.0)]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["results.take(1)"]},{"cell_type":"markdown","metadata":{},"source":["The last two values are notably `probability` and `prediction`.\n","\n","We will check how well the model performs by using AUROC and AUPR:"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Area under ROC: 0.9944933323696312\n"," Area under PR: 0.9953270478148899\n"]}],"source":["print('Area under ROC:', evaluator.evaluate(results, {evaluator.metricName: 'areaUnderROC'}))\n","print(' Area under PR:', evaluator.evaluate(results, {evaluator.metricName: 'areaUnderPR'}))"]},{"cell_type":"markdown","metadata":{},"source":["Since scores close to 1 indicate excellent performance, our model is performing very well at both distinguishing between the 2 genders and also maintaining high precision and recall."]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":1}